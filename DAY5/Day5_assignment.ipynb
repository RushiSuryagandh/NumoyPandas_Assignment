{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import os\n",
    "import shutil # Module offers a number of high-level operations on files and collections of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "###### 1. Get weather information from url: \n",
    "###### https://www.accuweather.com/en/in/mumbai/204842/weather-forecast/204842 \n",
    "###### 1. Make use beautiful soup and selenium.  \n",
    "###### 2. Extract day, high temperature, low temperature, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today :Sat, Feb 1\n",
      "High_temperature:30째\n",
      "LOw_temperature:17째\n"
     ]
    }
   ],
   "source": [
    "def extract_data_bs4():\n",
    "    url='https://www.accuweather.com/en/in/mumbai/204842/weather-forecast/204842'\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "    r=requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(r.content,'html5lib')\n",
    "    # print(soup.prettify())\n",
    "    div=soup.find_all('div',{'class':'today-forecast-card content-module'})\n",
    "    for d in div:\n",
    "        date_and_day=d.find('p',{'class':'sub'})\n",
    "        high_temp = d.find('b').text.split('Hi: ')[1]\n",
    "        low_temp = d.find_all('b')[1].text.split('Lo: ')[1]\n",
    "\n",
    "    print(f'Today :{date_and_day.text.strip()}')\n",
    "    print(f'High_temperature:{high_temp}')\n",
    "    print(f'LOw_temperature:{low_temp}')\n",
    "\n",
    "extract_data_bs4()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today :Sat, Feb 1\n",
      "Hi: 30째\n",
      "Lo: 17째\n"
     ]
    }
   ],
   "source": [
    "def extract_data_using_selenium():\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.get('https://www.accuweather.com/en/in/mumbai/204842/weather-forecast/204842') # opening the link\n",
    "    driver.implicitly_wait(5)\n",
    "    data=driver.find_element(By.XPATH,'/html/body/div/div[7]/div[1]/div[1]/div[1]/a').get_attribute('outerHTML') # getting data in html format\n",
    "    # data=driver.page_source\n",
    "    # print(data)\n",
    "    driver.quit()\n",
    "    soup=BeautifulSoup(data,'html.parser') # parse thr html\n",
    "    # print(soup.prettify())\n",
    "    today=soup.find('p',{'class':'sub'})\n",
    "    Temp=soup.find_all('b')\n",
    "    print(f'today :{today.text.strip()}')\n",
    "    for t in Temp:\n",
    "        print(t.text)\n",
    "extract_data_using_selenium()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "###### Customer Threads: \n",
    "###### 1. Each customer is represented by a separate thread in the system. \n",
    "###### 2. When a customer arrives at the coffee shop, they start a new thread \n",
    "###### (representing their order) and place their order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer 1 is ordering a Small Latte with Almond Milk.\n",
      "Customer 2 is ordering a Medium Latte with Skim Milk.\n",
      "Customer 3 is ordering a Large Cappuccino with Almond Milk.\n",
      "Customer 4 is ordering a Medium Cappuccino with Simple Milk.\n",
      "Customer 5 is ordering a Small Latte with Almond Milk.\n",
      "Customer 3's Large Cappuccino with Almond Milk is ready! (Took 4 seconds)\n",
      "Customer 1's Small Latte with Almond Milk is ready! (Took 4 seconds)\n",
      "Customer 4's Medium Cappuccino with Simple Milk is ready! (Took 4 seconds)\n",
      "Customer 5's Small Latte with Almond Milk is ready! (Took 4 seconds)\n",
      "Customer 2's Medium Latte with Skim Milk is ready! (Took 4 seconds)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def place_order(customer_id):\n",
    "    \n",
    "    coffee_types = ['Espresso', 'Latte', 'Cappuccino']\n",
    "    milk_types = ['Simple Milk', 'Skim Milk', 'Almond Milk']\n",
    "    sizes = ['Small', 'Medium', 'Large']\n",
    "    coffee = random.choice(coffee_types)\n",
    "    milk = random.choice(milk_types)\n",
    "    size = random.choice(sizes)\n",
    "\n",
    "   \n",
    "    print(f\"Customer {customer_id} is ordering a {size} {coffee} with {milk}.\")\n",
    "    \n",
    "    \n",
    "    time.sleep(4)\n",
    "    \n",
    "    print(f\"Customer {customer_id}'s {size} {coffee} with {milk} is ready! (Took {4} seconds)\")\n",
    "\n",
    "\n",
    "def simulate_coffee_shop(num_customers):\n",
    "    threads = []\n",
    "\n",
    "    \n",
    "    for customer_id in range(1, num_customers + 1):\n",
    "        thread = threading.Thread(target=place_order, args=(customer_id,))\n",
    "        threads.append(thread)\n",
    "        thread.start()  # Start the thread\n",
    "\n",
    "   \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "\n",
    "\n",
    "simulate_coffee_shop(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "###### Following is the url where it generates new picture every time when got hit. \n",
    "###### 1. https://picsum.photos/2000/3000 \n",
    "###### 2. Use this url and download images 5 times using multiprocessing module \n",
    "###### 3. Check execution time with and without multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Multithreading Download Images\n",
    "cd=os.getcwd()\n",
    "cd=cd+\"/output/\"\n",
    "url='https://stocksnap.io/search/nature'\n",
    "headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246\"}\n",
    "r=requests.get(url,headers=headers)\n",
    "soup=BeautifulSoup(r.content,'html5lib')\n",
    "# print(soup.prettify())\n",
    "data=soup.find_all('img')\n",
    "urls=data[20:]\n",
    "# print(urls)\n",
    "def save_image(a):\n",
    "    for a in urls:\n",
    "        image=a.get('src')\n",
    "        print(image)\n",
    "        file_name=a.get('src').split(\"/\")[-1]\n",
    "        data=requests.get(image,stream=True)\n",
    "        data.raw.decode_content=True\n",
    "        with open(cd+file_name,'w+b') as f1:\n",
    "            shutil.copyfileobj(data.raw,f1)\n",
    "            f1.close()\n",
    "        print(file_name)\n",
    "\n",
    "for i in range(len(urls)):\n",
    "    save_image(urls[i])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequential download...\n",
      "<Response [200]>\n",
      "Downloaded image_0.jpg\n",
      "<Response [200]>\n",
      "Downloaded image_1.jpg\n",
      "Sequential download took: 8.19 seconds\n",
      "\n",
      "Starting multiprocessing download...\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from multiprocessing import Pool\n",
    "import requests\n",
    "import time\n",
    "# URL for downloading the images\n",
    "url = \"https://picsum.photos/2000/3000\"\n",
    " \n",
    "# Function to download an image\n",
    "def download_image(index):\n",
    "    response = requests.get(url)\n",
    "    print(response)\n",
    "    if response.status_code == 200:\n",
    "        with open(f\"./output/image_{index}.jpg\", \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded image_{index}.jpg\")\n",
    "\n",
    " \n",
    "# # Without multiprocessing (sequential download)\n",
    "def download_images_sequential():  # Took 12.72 Second\n",
    "    start_time = time.time()\n",
    "    for i in range(2):\n",
    "        download_image(i)\n",
    "    end_time = time.time()\n",
    "    print(f\"Sequential download took: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    " \n",
    "# # With multiprocessing (download)\n",
    "def download_images_multiprocessing():\n",
    "    start_time = time.time()\n",
    "    p=Pool()\n",
    "    l=[x for x in range(5)]\n",
    "    p.map(download_image,l)\n",
    "    # print(data)\n",
    "    end_time = time.time()\n",
    "    print(f\"Multiprocessing download took: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    " \n",
    "# # Run both functions to compare the execution times\n",
    "print(\"Starting sequential download...\")\n",
    "download_images_sequential()\n",
    " \n",
    "print(\"\\nStarting multiprocessing download...\")\n",
    "download_images_multiprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
